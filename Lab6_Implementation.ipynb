{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [0, 1], [0, 2], [0, 3], [1, 0], [1, 1], [1, 2], [1, 3], [2, 0], [2, 1], [2, 2], [2, 3], [3, 0], [3, 1], [3, 2], [3, 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%pylab inline\n",
    "import random\n",
    "\n",
    "# parameters\n",
    "gridSize = 4\n",
    "states_terminal = [[0,0], [gridSize-1, gridSize-1]]\n",
    "valid_actions = [[-1, 0], [1, 0], [0, 1], [0, -1]]\n",
    "gamma = 0.1 # discount rate\n",
    "currentReward = -1\n",
    "#Those values seem to work well\n",
    "numIterations = 100\n",
    "alpha = 0.1 #exploration factor\n",
    "\n",
    "# initialization\n",
    "#Note: Shouldn't the Q matrix be of dimension mxn instead, where m is the size of the state space and n is the size of the action space?\n",
    "Q = np.zeros((gridSize, len(valid_actions)))\n",
    "states = [[i, j] for i in range(gridSize) for j in range(gridSize)]\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange, choice\n",
    "def generateInitialState():\n",
    "    #generate a random initial state\n",
    "    #Pick any state but the terminal states\n",
    "    initialState = randrange(1, gridSize**2 - 1)\n",
    "    return states[initialState]\n",
    "\n",
    "def generateNextAction(state):\n",
    "    #generate a random action from the valid set of actions\n",
    "    #Pick completely random with probability alpha being the exploration rate\n",
    "    if np.random.uniform(0, 1) < alpha:\n",
    "        nextAction = randrange(0, len(valid_actions))\n",
    "        return nextAction\n",
    "    #Pick from Q table otherwise\n",
    "    #(From all currently possible actions, pick the one that maximises the reward for this specific state)\n",
    "    nextAction = np.argmax(Q[state, :])\n",
    "    return nextAction\n",
    "\n",
    "# define the transition function from a given state and action\n",
    "def getNextState(state, action):\n",
    "    \n",
    "    #define what happens when reaching a terminal state\n",
    "    if state in states_terminal:\n",
    "        return None, None\n",
    "    \n",
    "    # here you should complete this step, the transition step\n",
    "    nextStateObj = [sum(result) for result in zip(state, valid_actions[action])]\n",
    "    # if the agent reaches a wall \n",
    "    if -1 in nextStateObj or gridSize in nextStateObj:\n",
    "        nextStateObj = state\n",
    "        nextState = state\n",
    "    else:\n",
    "        nextState = nextStateObj\n",
    "    return currentReward, nextState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kj/r4bf7thj1gg5bp153_b6nf740000gn/T/ipykernel_42102/1162107025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mcurrentAction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateNextAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetNextState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentAction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m#complete the stop action if the agent reached the goal state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnextState\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kj/r4bf7thj1gg5bp153_b6nf740000gn/T/ipykernel_42102/2272842293.py\u001b[0m in \u001b[0;36mgetNextState\u001b[0;34m(state, action)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# here you should complete this step, the transition step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mnextStateObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# if the agent reaches a wall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnextStateObj\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgridSize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnextStateObj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for it in range(numIterations):\n",
    "    currentState = generateInitialState()\n",
    "    while True:\n",
    "        currentAction = generateNextAction(currentState)\n",
    "        reward, nextState = getNextState(currentState, currentAction)\n",
    "        #complete the stop action if the agent reached the goal state\n",
    "        if reward is None and nextState is None:\n",
    "            break\n",
    "        #update the Q-value function Q\n",
    "        nextAction = generateNextAction(nextState)\n",
    "        Q[currentState[0]][currentState[1]] = (1 - alpha) * Q[currentState[0]][currentState[1]] + alpha * (reward + gamma * Q[nextState[0]][nextState[1]])\n",
    "        #assign as current state the next state\n",
    "        currentState = nextState\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: [0, 0] Action: 0\n",
      "State: [0, 1] Action: 3\n",
      "State: [0, 2] Action: 3\n",
      "State: [0, 3] Action: 3\n",
      "State: [1, 0] Action: 0\n",
      "State: [1, 1] Action: 3\n",
      "State: [1, 2] Action: 3\n",
      "State: [1, 3] Action: 1\n",
      "State: [2, 0] Action: 0\n",
      "State: [2, 1] Action: 1\n",
      "State: [2, 2] Action: 2\n",
      "State: [2, 3] Action: 1\n",
      "State: [3, 0] Action: 0\n",
      "State: [3, 1] Action: 2\n",
      "State: [3, 2] Action: 2\n",
      "State: [3, 3] Action: 0\n"
     ]
    }
   ],
   "source": [
    "#Print the desired action for each state\n",
    "for i in range(len(Q)):\n",
    "    print(\"State: \" + str(states[i]) + f\" Action: {np.argmax(Q[i, :])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 3. 3. 3.]\n",
      " [0. 3. 3. 1.]\n",
      " [0. 1. 2. 1.]\n",
      " [0. 2. 2. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data = np.zeros((gridSize, gridSize))\n",
    "for i in range(len(states)):\n",
    "    data[states[i][0], states[i][1]] = np.argmax(Q[i, :])\n",
    "print(data)\n",
    "#0 = up, 1 = down, 2 = right, 3 = left"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
